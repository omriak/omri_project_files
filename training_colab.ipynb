{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owL_d1x9ujDL"
   },
   "outputs": [],
   "source": [
    "/content/training_data_arrange_A001.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "epGjszRPvGLd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, Resizing\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDrm_PsBvHLD",
    "outputId": "ffe33463-985a-47c8-f4d9-857a15dfac5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your data path: /content/A001\n",
      "/content/training_data_arrange_A001.npy\n"
     ]
    }
   ],
   "source": [
    "def upsample_100(data):\n",
    "    current_N = np.shape(data)\n",
    "    new_data = np.zeros(shape=(100,current_N[1],current_N[2]))\n",
    "    for i in range(0,100):\n",
    "        new_data[i,:,:] = data[int(np.floor((current_N[0]*i)/100)),:,:]\n",
    "    return new_data\n",
    "\n",
    "def DFS():\n",
    "    DFS_indexlist = np.array([2, 21, 9, 10,  11,  12, 25,  12,  24,  12,  11, 10, 9,\n",
    "                             21, 3, 4, 3, 21, 5, 6, 7, 8, 23, 8, 22, 8, 7, 6, 5, 21,\n",
    "                             2, 1, 13, 14, 15, 16, 15, 14, 13, 1, 17, 18, 19, 20, 19,\n",
    "                             18, 17, 1, 2])\n",
    "    DFS_indexlist = DFS_indexlist-1\n",
    "    return DFS_indexlist\n",
    "\n",
    "# Nicely formatted time string\n",
    "\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# paths and variables\n",
    "# main path:\n",
    "path_folder = '/content/'\n",
    "\n",
    "# action folder:\n",
    "# only one action.\n",
    "action_folder = 'A001'  \n",
    "\n",
    "# file_name='S001C001P001R002A001.skeleton.npy' example.\n",
    "\n",
    "\n",
    "DATA_PATH=os.path.join(path_folder,action_folder)\n",
    "DATA_PATH_A=os.path.join(path_folder)\n",
    "print(f\"your data path: {DATA_PATH}\")\n",
    "\n",
    "#loading the training data.\n",
    "training_binary_path = os.path.join(DATA_PATH_A,f'training_data_arrange_{action_folder}.npy')\n",
    "print(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkP4z6QfvoI4",
    "outputId": "8c677ffe-31a4-4c45-ca28-2eb1e6793f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous training pickle...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading previous training pickle...\")\n",
    "training_data = np.load(training_binary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rFwGablGxMgV"
   },
   "outputs": [],
   "source": [
    "def build_image_resizer(height,width):\n",
    "    model = Sequential()\n",
    "    model.add(Resizing(64, 64, interpolation=\"bilinear\" , input_shape=(height,width,3)))\n",
    "    return model\n",
    "\n",
    "def build_generator(seed_size):\n",
    "    # seed_size is z+c where c is the class sagment\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer\n",
    "    model.add(Dense(4*4*512,activation=\"relu\",input_dim=seed_size)) \n",
    "    model.add(Reshape((4,4,512)))\n",
    "\n",
    "    # Mid CNN layer\n",
    "    model.add(UpSampling2D(size=2,interpolation = 'bilinear'))\n",
    "    model.add(Conv2D(512,kernel_size=(3,3),strides = (1, 1),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D(size=(2, 2),interpolation = 'bilinear'))\n",
    "    model.add(Conv2D(256,kernel_size=(3,3),strides = (1, 1),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(UpSampling2D(size=(2, 2),interpolation = 'bilinear'))\n",
    "    model.add(Conv2D(128,kernel_size=(3,3),strides = (1, 1),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    model.add(UpSampling2D(size=(2, 2),interpolation = 'bilinear'))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),strides = (1, 1),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    \n",
    "    # Final CNN layer\n",
    "    model.add(UpSampling2D(size=(2, 2),interpolation = 'bilinear'))\n",
    "    model.add(Conv2D(3,kernel_size=(3,3),strides = (1, 1),padding=\"same\",use_bias = False))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Resizing(64, 64, interpolation=\"bilinear\" , input_shape=(128,128,3)))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #input layer first using resizer\n",
    "    model.add(Conv2D(64, kernel_size=(4,4), strides=(2,2), input_shape=image_shape, padding=\"same\",use_bias = False))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(4,4), strides=(2,2),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(4,4), strides=(2,2),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(4,4), strides=(2,2),padding=\"same\",use_bias = False))\n",
    "    model.add(BatchNormalization(epsilon=10**-5,momentum=0.1))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de_y6eHyxcxh",
    "outputId": "603d015f-9576-482c-a74c-c0d915636db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_3 (Resizing)       (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 8192)              876544    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " up_sampling2d_5 (UpSampling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 512)         2359296   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 16, 16, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 256)       1179648   \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 32, 32, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 32, 128)       294912    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 64, 64, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 64, 64, 64)        73728     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 128, 128, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 3)       1728      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " resizing_2 (Resizing)       (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,789,696\n",
      "Trainable params: 4,787,776\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 32, 32, 64)        9216      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 128)       131072    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 8, 8, 256)         524288    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 4, 4, 512)         2097152   \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,773,505\n",
      "Trainable params: 2,771,713\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator(106)\n",
    "discriminator = build_discriminator((64,64,9))\n",
    "resizer = build_image_resizer(100,49)\n",
    "Model.summary(resizer)\n",
    "Model.summary(generator)\n",
    "Model.summary(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IL2fd0s8xhfR"
   },
   "outputs": [],
   "source": [
    "#traning module\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def add_class(images):\n",
    "    images = images.numpy()\n",
    "    s = images.shape\n",
    "    zero = np.zeros((s[0], s[1], s[2], 5))  \n",
    "    one = np.ones((s[0], s[1], s[2], 1)) \n",
    "    class1 = np.append(zero, one, axis=3)\n",
    "    return  np.append(images, class1, axis=3)\n",
    "    \n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1.5e-4,0.5)\n",
    "\n",
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images,seed):\n",
    "    generator_resizer = build_image_resizer(128,128)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape: \n",
    "        generated_images = generator(seed, training=True)\n",
    "        generated_images = tf.concat([generated_images,tf.zeros((generated_images.shape[0],64,64,5)), tf.ones((generated_images.shape[0],64,64,1))], 3)\n",
    "        #generated_images = generator_resizer(generated_images, training=False)\n",
    "        #proto_tensor = tf.make_tensor_proto(generated_images)\n",
    "        #generated_images = tf.make_ndarray(proto_tensor)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "    \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables),\n",
    "    experimental_aggregate_gradients=False)\n",
    "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables),\n",
    "    experimental_aggregate_gradients=False)\n",
    "    return gen_loss,disc_loss\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    seed = np.random.normal(0, 1,100)\n",
    "    c = np.asarray((0,0,0,0,0,1))\n",
    "    fixed_seed = np.append(seed,c)\n",
    "    \n",
    "    seed = np.random.normal(0, 1,(BATCH_SIZE,100))\n",
    "    s = seed.shape\n",
    "    zero = np.zeros((s[0], 5))  \n",
    "    one = np.ones((s[0], 1)) \n",
    "    class1 = np.append(zero, one, axis=1)\n",
    "    seed = np.append(seed, class1, axis=1)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        gen_loss_list = []\n",
    "        disc_loss_list = []\n",
    "        #i=0\n",
    "        for image_batch in dataset:\n",
    "            t = train_step(image_batch,seed)\n",
    "            gen_loss_list.append(t[0])\n",
    "            disc_loss_list.append(t[1])\n",
    "            #i = i+1\n",
    "            #print('image_batch'+str(i))\n",
    "\n",
    "        g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "        d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "        epoch_elapsed = time.time()-epoch_start\n",
    "        print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'f' {hms_string(epoch_elapsed)}')\n",
    "        #save_images(epoch,fixed_seed)\n",
    "\n",
    "    elapsed = time.time()-start\n",
    "    print (f'Training time: {hms_string(elapsed)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1kaZGfQxloh",
    "outputId": "6a80bbd8-a642-47b8-fd43-9f35f02c3d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(939, 64, 64, 3)\n",
      "(939, 64, 64, 9)\n"
     ]
    }
   ],
   "source": [
    "training_data_r = resizer(training_data, training=False)\n",
    "print(training_data_r.shape)\n",
    "s = training_data_r.shape\n",
    "zero = np.zeros((s[0], s[1], s[2], 5))  \n",
    "one = np.ones((s[0], s[1], s[2], 1)) \n",
    "class1 = np.append(zero, one, axis=3)\n",
    "training_data_r1 = np.append(training_data_r, class1, axis=3)\n",
    "print(training_data_r1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OHuxJ0FxsZU",
    "outputId": "7f61a7b5-68cf-4335-861d-7717b4d30eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, gen loss=1.554563283920288,disc loss=0.9927493929862976, 0:00:09.83\n",
      "Epoch 2, gen loss=1.41997230052948,disc loss=1.0119458436965942, 0:00:09.63\n",
      "Epoch 3, gen loss=1.0515707731246948,disc loss=1.3734499216079712, 0:00:10.32\n",
      "Epoch 4, gen loss=0.9107743501663208,disc loss=1.3108322620391846, 0:00:09.58\n",
      "Epoch 5, gen loss=1.0469051599502563,disc loss=1.16452956199646, 0:00:09.57\n",
      "Epoch 6, gen loss=1.2579561471939087,disc loss=1.1443970203399658, 0:00:09.59\n",
      "Epoch 7, gen loss=1.6970362663269043,disc loss=0.8603763580322266, 0:00:09.56\n",
      "Epoch 8, gen loss=1.4362508058547974,disc loss=1.0911551713943481, 0:00:09.56\n",
      "Epoch 9, gen loss=1.4579707384109497,disc loss=1.119246006011963, 0:00:09.69\n",
      "Epoch 10, gen loss=1.7963359355926514,disc loss=0.7587465643882751, 0:00:09.57\n",
      "Epoch 11, gen loss=1.6800841093063354,disc loss=0.9964626431465149, 0:00:09.56\n",
      "Epoch 12, gen loss=2.103480815887451,disc loss=0.6586953401565552, 0:00:09.57\n",
      "Epoch 13, gen loss=1.6975419521331787,disc loss=0.968756914138794, 0:00:09.58\n",
      "Epoch 14, gen loss=2.150357246398926,disc loss=0.7244129776954651, 0:00:09.56\n",
      "Epoch 15, gen loss=2.1297762393951416,disc loss=0.5917442440986633, 0:00:09.53\n",
      "Epoch 16, gen loss=2.2426156997680664,disc loss=0.7899503111839294, 0:00:09.57\n",
      "Epoch 17, gen loss=2.0079612731933594,disc loss=0.7891597747802734, 0:00:09.54\n",
      "Epoch 18, gen loss=2.009589672088623,disc loss=0.6998744606971741, 0:00:09.54\n",
      "Epoch 19, gen loss=2.226621150970459,disc loss=0.8801769614219666, 0:00:09.54\n",
      "Epoch 20, gen loss=1.867812991142273,disc loss=0.7929671406745911, 0:00:09.55\n",
      "Epoch 21, gen loss=2.2023062705993652,disc loss=0.5778032541275024, 0:00:09.53\n",
      "Epoch 22, gen loss=2.260711908340454,disc loss=0.7047123312950134, 0:00:09.55\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 60000\n",
    "SEED_SIZE = 106\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(training_data_r1).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "#print(train_dataset.size)\n",
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Welcome To Colaboratory",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
